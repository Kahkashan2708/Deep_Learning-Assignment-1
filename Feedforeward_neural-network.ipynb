{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5de5a82b-378f-4825-86fe-a6441d339083",
   "metadata": {},
   "source": [
    "# **$$Question-2$$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac26bef8-da12-448a-80b7-dc7e0b76d9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f32c450-bec0-4c4c-a2ef-53bf5c86a880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Fashion-MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57fd4cbc-444a-4c34-87b3-61c1a0454f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bc74245-0363-479b-bba3-bdf70f886b5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a40ac59a-6224-4ab4-b312-b4e668cf2eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d83b3324-0081-4817-b7a1-9fe928a86ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "x_train = x_train.reshape(x_train.shape[0], -1) / 255.0  # Flatten to (60000, 784)\n",
    "x_test = x_test.reshape(x_test.shape[0], -1) / 255.0  # Flatten to (10000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa4ac2c7-5256-48fa-8e6c-cbcefa4bfb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding\n",
    "def one_hot_encode(y, num_classes=10):\n",
    "    return np.eye(num_classes)[y]\n",
    "\n",
    "y_train = one_hot_encode(y_train)\n",
    "y_test = one_hot_encode(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "446a18db-b947-4c55-bf96-e3ec6156a49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation Functions(ReLu and Softmax)\n",
    "def relu(Z):\n",
    "    return np.maximum(0, Z)\n",
    "\n",
    "def softmax(Z):\n",
    "    exp_Z = np.exp(Z - np.max(Z, axis=1, keepdims=True)) \n",
    "    return exp_Z / np.sum(exp_Z, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6857ecb0-336c-4cc8-b2aa-ae6a3e495d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derivatives\n",
    "def relu_derivative(Z):\n",
    "    return (Z > 0).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70217658-e814-4b58-9dac-a9cfae224e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Function (Cross-Entropy)\n",
    "def cross_entropy_loss(y_true, y_pred):\n",
    "    return -np.mean(np.sum(y_true * np.log(y_pred + 1e-8), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e80fed0-9b56-4ccd-a349-eb63237ae035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network Class(forward and backward Propagation)\n",
    "class FeedforwardNN:\n",
    "    def __init__(self, input_size=784, hidden_layers=[256,128, 64], output_size=10, lr=0.05):\n",
    "        self.lr = lr\n",
    "        self.layers = [input_size] + hidden_layers + [output_size]\n",
    "\n",
    "        # Initialize weights and biases\n",
    "        self.params = {}\n",
    "        for i in range(1, len(self.layers)):\n",
    "            self.params[f\"W{i}\"] = np.random.randn(self.layers[i-1], self.layers[i]) * np.sqrt(2 / self.layers[i-1]) \n",
    "            self.params[f\"b{i}\"] = np.zeros((1, self.layers[i]))\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.cache = {\"A0\": X}  # (Input layer)\n",
    "        for i in range(1, len(self.layers) - 1):\n",
    "            self.cache[f\"Z{i}\"] = np.dot(self.cache[f\"A{i-1}\"], self.params[f\"W{i}\"]) + self.params[f\"b{i}\"]\n",
    "            self.cache[f\"A{i}\"] = relu(self.cache[f\"Z{i}\"])  # ReLU (for hidden layers)\n",
    "\n",
    "        # Output Layer (Softmax)\n",
    "        L = len(self.layers) - 1\n",
    "        self.cache[f\"Z{L}\"] = np.dot(self.cache[f\"A{L-1}\"], self.params[f\"W{L}\"]) + self.params[f\"b{L}\"]\n",
    "        self.cache[f\"A{L}\"] = softmax(self.cache[f\"Z{L}\"])  \n",
    "\n",
    "        return self.cache[f\"A{L}\"]\n",
    "\n",
    "    def backward(self, X, y_true):\n",
    "        grads = {}\n",
    "        L = len(self.layers) - 1\n",
    "        m = X.shape[0]\n",
    "\n",
    "        # Output layer error (Softmax derivative with Cross-Entropy)\n",
    "        dZ = self.cache[f\"A{L}\"] - y_true\n",
    "        grads[f\"W{L}\"] = (1 / m) * np.dot(self.cache[f\"A{L-1}\"].T, dZ)\n",
    "        grads[f\"b{L}\"] = (1 / m) * np.sum(dZ, axis=0, keepdims=True)\n",
    "\n",
    "        # Backpropagation through hidden layers\n",
    "        for i in range(L-1, 0, -1):\n",
    "            dA = np.dot(dZ, self.params[f\"W{i+1}\"].T)\n",
    "            dZ = dA * relu_derivative(self.cache[f\"Z{i}\"])  \n",
    "            grads[f\"W{i}\"] = (1 / m) * np.dot(self.cache[f\"A{i-1}\"].T, dZ)\n",
    "            grads[f\"b{i}\"] = (1 / m) * np.sum(dZ, axis=0, keepdims=True)\n",
    "\n",
    "        # Update weights\n",
    "        for i in range(1, len(self.layers)):\n",
    "            self.params[f\"W{i}\"] -= self.lr * grads[f\"W{i}\"]\n",
    "            self.params[f\"b{i}\"] -= self.lr * grads[f\"b{i}\"]\n",
    "\n",
    "    def train(self, X, y, epochs=10, batch_size=64):\n",
    "        for epoch in range(epochs):\n",
    "            for i in range(0, X.shape[0], batch_size):\n",
    "                X_batch = X[i:i+batch_size]\n",
    "                y_batch = y[i:i+batch_size]\n",
    "\n",
    "                self.forward(X_batch)\n",
    "                self.backward(X_batch, y_batch)\n",
    "\n",
    "            # loss for every epoch\n",
    "            loss = cross_entropy_loss(y, self.forward(X))\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss:.4f}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        probabilities = self.forward(X)\n",
    "        return np.argmax(probabilities, axis=1)\n",
    "\n",
    "    def evaluate(self, X, y):\n",
    "        predictions = self.predict(X)\n",
    "        true_labels = np.argmax(y, axis=1)\n",
    "        accuracy = np.mean(predictions == true_labels)\n",
    "        print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20c012ed-5309-49f8-9e22-e239a024599a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.4464\n",
      "Epoch 2/20, Loss: 0.4167\n",
      "Epoch 3/20, Loss: 0.3961\n",
      "Epoch 4/20, Loss: 0.3525\n",
      "Epoch 5/20, Loss: 0.3380\n",
      "Epoch 6/20, Loss: 0.3006\n",
      "Epoch 7/20, Loss: 0.2984\n",
      "Epoch 8/20, Loss: 0.2939\n",
      "Epoch 9/20, Loss: 0.2716\n",
      "Epoch 10/20, Loss: 0.2828\n",
      "Epoch 11/20, Loss: 0.2686\n",
      "Epoch 12/20, Loss: 0.2504\n",
      "Epoch 13/20, Loss: 0.2420\n",
      "Epoch 14/20, Loss: 0.2372\n",
      "Epoch 15/20, Loss: 0.2357\n",
      "Epoch 16/20, Loss: 0.2206\n",
      "Epoch 17/20, Loss: 0.2210\n",
      "Epoch 18/20, Loss: 0.2141\n",
      "Epoch 19/20, Loss: 0.2121\n",
      "Epoch 20/20, Loss: 0.2019\n"
     ]
    }
   ],
   "source": [
    "# Train the Model\n",
    "nn = FeedforwardNN(hidden_layers=[256,128, 64]) \n",
    "nn.train(x_train, y_train, epochs=20, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d314dfb4-cbd8-4319-a924-13cd325b3386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 92.31%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.9230666666666667)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the Train Data \n",
    "nn.evaluate(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ff3b268-bc58-4727-a2ea-2210d78c80b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 87.95%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.8795)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate on Test Data\n",
    "nn.evaluate(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
